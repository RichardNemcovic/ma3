{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI & Machine Learning (KAN-CINTO4003U) - Copenhagen Business School | Spring 2025**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"media/tools_header.webp\" alt=\"LLM\" width=\"800\"/> <br>\n",
    "Image from <a href=\"https://medium.com/@lorevanoudenhove\">Lore Van Oudenhove<a/>'s \"<i><a href=\"https://medium.com/@lorevanoudenhove/how-to-build-ai-agents-with-langgraph-a-step-by-step-guide-5d84d9c7e832\">How to Build AI Agents with LangGraph</a></i>\". <br>Copyright Â© 2025. All rights reserved.\n",
    "</p>\n",
    "\n",
    "***\n",
    "Sources: <br>\n",
    "- [How to Build AI Agents with LangGraph (Lore Van Oudenhove via Medium)](https://medium.com/@lorevanoudenhove/how-to-build-ai-agents-with-langgraph-a-step-by-step-guide-5d84d9c7e832)\n",
    "\n",
    "\n",
    "# Tool-using LLM agents\n",
    "\n",
    "In [`guides/router_agents.ipynb`](router_agents_guide.ipynb), we built a simple `router` agent. This introduces us to the concept of using LLMs as reasoning engines that influence which steps to take to complete a task. In this notebook, we will build on this concept and create a more complex agent that can use tools to complete tasks.\n",
    "\n",
    "As last time, an LLM Agent will\n",
    "\n",
    "1. Receive a sensory input (e.g. a text)\n",
    "2. Decide what to do with it\n",
    "3. Take an action (e.g. generate a summary)\n",
    "\n",
    "However, for tool using agents, these steps are taken in a loop. The agent will receive an input, decide what to do with it, take an action, and then receive the output of that action as input for the next step. This process continues until the agent decides to stop.\n",
    "\n",
    "As in the last notebook, we will be using [LangGraph](https://langchain-ai.github.io/langgraph/) to build our agent. The prior notebook introduces important concepts like `StateGraph`, `State`, `Node`, and `Edge`. Please make sure to start there.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langgraph/langchain libraries\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_ibm import ChatWatsonx\n",
    "from langchain_ibm import WatsonxEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.tools import tool\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "# misc libraries\n",
    "import requests\n",
    "from decouple import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading our WatsonX.ai credentials again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WX_API_KEY = config(\"WX_API_KEY\")\n",
    "WX_PROJECT_ID = config(\"WX_PROJECT_ID\")\n",
    "WX_API_URL = \"https://us-south.ml.cloud.ibm.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `ChatWatsonx` class from `langchain_ibm` - a LangChain wrapper for WatsonX.ai - to create a chat model. . We can use it to create a chat model that can be used in LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatWatsonx(\n",
    "    url=WX_API_URL,\n",
    "    apikey=WX_API_KEY,\n",
    "    project_id=WX_PROJECT_ID,\n",
    "    model_id=\"mistralai/mistral-large\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a prebuilt agent architecture\n",
    "\n",
    "LangGraph offers a prebuilt agent architecture that we can use simply by calling `create_react_agent`. This function takes as inputs (among other more advanced options)\n",
    "\n",
    "- model: the LLM model to use (In our case `ChatWatsonx`)\n",
    "- tools: the tools to use as a list\n",
    "\n",
    "So, first we need to define some tools. We can easily do so by using the `@tool` decoractor from `langgraph` as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def subtract(a: float, b: float) -> float:\n",
    "    \"\"\"Subtract a and b.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def divide(a: float, b: float) -> float:\n",
    "    \"\"\"Divide a and b.\"\"\"\n",
    "    return a / b\n",
    "\n",
    "# and to make it a little more interesting, let's add a currency converter\n",
    "@tool\n",
    "def get_exchange_rate(\n",
    "    currency_from: str = \"USD\",\n",
    "    currency_to: str = \"EUR\",\n",
    "    currency_date: str = \"latest\",\n",
    "):\n",
    "    \"\"\"Retrieves the exchange rate between two currencies on a specified date.\n",
    "\n",
    "    Uses the Frankfurter API (https://api.frankfurter.app/) to obtain\n",
    "    exchange rate data.\n",
    "\n",
    "    Args:\n",
    "        currency_from: The base currency (3-letter currency code).\n",
    "            Defaults to \"USD\" (US Dollar).\n",
    "        currency_to: The target currency (3-letter currency code).\n",
    "            Defaults to \"EUR\" (Euro).\n",
    "        currency_date: The date for which to retrieve the exchange rate.\n",
    "            Defaults to \"latest\" for the most recent exchange rate data.\n",
    "            Can be specified in YYYY-MM-DD format for historical rates.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the exchange rate information.\n",
    "            Example: {\"amount\": 1.0, \"base\": \"USD\", \"date\": \"2023-11-24\",\n",
    "                \"rates\": {\"EUR\": 0.95534}}\n",
    "    \"\"\"\n",
    "    response = requests.get(\n",
    "        f\"https://api.frankfurter.app/{currency_date}\",\n",
    "        params={\"from\": currency_from, \"to\": currency_to},\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "tools = [add, subtract, multiply, divide, get_exchange_rate]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our final list of tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with our model and tools defined, we can create our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_react_agent(chat_model, tools=tools, debug=True)\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"messages\": [\n",
    "        (\n",
    "            \"user\", \"I have 833 USD and my sister has 38 USD. How much do we have total in euros?\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "# we set the debug flag to True to print tasks and their results\n",
    "response = graph.invoke(inputs, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our response will be a set of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the last AIMessage will be the final response from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a RAG tool\n",
    "\n",
    "Let's see how we can add a RAG tool to our agent. We can use the `create_retriever_tool` from `langgraph` to create a retriever tool. This tool will allow the agent to retrieve information from a knowledge base and use it to answer questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already run everything in the [`rag_guide.ipynb`](rag_guide.ipynb) notebook, you will already have a local vector DB (by default called `my_vector_db`) with some documents in it. If you haven't, please run the notebook first to create the vector DB. You can also use any other vector DB you have access to.\n",
    "\n",
    "Since we will also have to embed incoming queries, we first need to define our embedding model here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_params = {}\n",
    "\n",
    "watsonx_embedding = WatsonxEmbeddings(\n",
    "    model_id=\"ibm/granite-embedding-278m-multilingual\",\n",
    "    url=WX_API_URL,\n",
    "    project_id=WX_PROJECT_ID,\n",
    "    apikey=WX_API_KEY,\n",
    "    params=embed_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's initialize our existing vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(collection_name=\"my_collection\", persist_directory=\"my_vector_db\", embedding_function=watsonx_embedding)\n",
    "\n",
    "vectordb.get(limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool = create_retriever_tool(\n",
    "    vectordb.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\n",
    "            \"k\": 3,\n",
    "        }\n",
    "    ),\n",
    "    \"retrieve_company_information\",\n",
    "    \"Search and return information about MadeUpCompany\",\n",
    ")\n",
    "\n",
    "tools_for_agent = [get_exchange_rate, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the vectorstore as a retriever\n",
    "retriever = vectordb.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": 3,\n",
    "    }\n",
    ")\n",
    "\n",
    "retrieved_documents = retriever.invoke(\"Do you have a 30-day money-back guarantee?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_react_agent(chat_model, tools=tools_for_agent, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke(\n",
    "    \n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\", \"What is CloudMate from MadeUpCompany? Keep it short and simple.\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    debug=True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke(\n",
    "    \n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\", \"What is the price of CloudMate Professional? Find the price first and then convert it to euros.\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    debug=True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = DuckDuckGoSearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_for_agent = [get_exchange_rate, retriever_tool, search_tool]\n",
    "\n",
    "graph = create_react_agent(chat_model, tools=tools_for_agent, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_for_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = graph.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\", \"Compare the price of CloudMate Professional from MadeUpCompany with the price of OneDrive from Microsoft. Find the price first and then convert it to euros.\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    debug=True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a many different tools to our react agent. You can find a list of all available tools in the [LangGraph documentation on tools](https://python.langchain.com/docs/integrations/tools/). Some of the most common tools are:\n",
    "\n",
    "- `Calculator`: A calculator tool that can perform basic arithmetic operations.\n",
    "- `Python`: A Python REPL that can execute Python code. (Be careful with this one, as it can execute any code you give it. This can be dangerous if you are not careful.)\n",
    "- `Office365 Toolkit`: A toolkit that can be used to interact with Office365 applications like Excel, Word, and PowerPoint.\n",
    "- `SQLDatabase Toolkit` : A toolkit that can be used to interact with SQL databases.\n",
    "- `ArXiv` : A tool that can be used to search for papers on ArXiv.\n",
    "\n",
    "\n",
    "One of the disadvantes of using the `create_react_agent` function is that it does not allow us to customize the agent's behavior much. If we want to customize the agent's behavior, we need to create our own agent using the `StateGraph` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-ma3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
